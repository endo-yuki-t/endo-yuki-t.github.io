<HTML>

<HEAD>
  <META http-equiv="content-type" content="text/html; charset=iso-8859-1">
  <TITLE>Diversifying Detail and Appearance in Sketch-Based Face Image Synthesis</TITLE>
  <style type="text/css">
    #wrap {
      width: 900px;
      margin-right: auto;
      margin-left: auto;
    }

    #wrap2 {
      width: 1440px;
      margin-right: auto;
      margin-left: auto;
    }
  </style>
</HEAD>

<BODY bgcolor="#FFFFFF">
  <div id="wrap">
    <H2 align="center">Diversifying Detail and Appearance in Sketch-Based Face Image Synthesis</H2>
  </div>
  <CENTER>
    <P><a href="http://www.cgg.cs.tsukuba.ac.jp/~yoshikawa/index.html">Takato Yoshikawa</a>, <a
        href="https://endo-yuki-t.github.io">Yuki Endo</a>, <a
        href="http://kanamori.cs.tsukuba.ac.jp/index.html">Yoshihiro Kanamori</a></P>
    <P>University of Tsukuba</P>
    <P>Computer Graphics Internatinal 2022</P>
    <BR>
    <div id="wrap"><img src="./teaser.png" width="100%" border="0"></div>
  </CENTER>

  <div id="wrap">
    <HR boader="1">
    <h3>Abstract:</h3>
    <p align="justify">
      Sketch-based face image synthesis has gained greater attention with the increasing realism of its output images.
      However, existing studies have overlooked the significance of output diversity: because sketches are inherently
      ambiguous, it would be desirable to have various output candidates for a single input sketch.
      In this paper, we explore synthesis of diverse face images from a single sketch by using a three-stage framework
      consisting of sketch refinement, detail enhancement, and appearance synthesis.
      Each stage uses supervised learning with neural networks.
      With this threestage framework, we can separately control the detail (e.g., wrinkles and hair structures) and
      appearance (e.g., skin and hair colors) of output face images separately by using multiple latent codes.
      Quantitative and quantitative evaluations demonstrate that our method offers greater diversity in its output
      images than the state-of-the-art methods, while retaining the output realism.</p>

    <p><b>Keywords</b>: Sketch-based image synthesis; Deep learning; GAN; Multimodal</p>

    <HR boader="1">
    <h3>Video:</h3>
    <CENTER>
      <iframe width="640" height="360" src="https://www.youtube.com/embed/p7L_x8X493o" title="YouTube video player"
        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen></iframe>
    </CENTER>
    <HR boader="1">
    <!-- <h3>Code: (published on ...)</h3>
    <ul>
      <li><a href="https://github.com/tenten0727/sketch_to_diverse_image">PyTorch Code<a></li>
      <li><a href="">Pre-trained Models<a> (... MB)</li>
    </ul>
    <HR boader="1"> -->

    <h3>Publication:</h3>
    <ol>
      <li>Takato Yoshikawa, Yuki Endo, Yoshihiro Kanamori: "Diversifying Detail and Appearance in Sketch-Based Face
        Image Synthesis" The Visual Computer (Proc. of Computer Graphics Internatinal 2022), 2022. [<a
          href="pdf/Yoshikawa_CGI2022.pdf">PDF</a>
        (2MB)][<a href="https://github.com/tenten0727/Sketch-to-diverse-image">Code</a>]
        <!-- todo:後日正式版が公開されたら、出版社URLを貼る -->
    </ol>

    <hr boader="1">
    <h3>BibTeX Citation</h3>
    <div style="padding: 10px; margin-bottom: 10px; border: 1px solid #333333;">
      <pre>@article{YoshikawaCGI22,
      author    = {Takato Yoshikawa and Yuki Endo and Yoshihiro Kanamori},
      title     = {Diversifying Detail and Appearance in Sketch-Based Face Image Synthesis},
      journal   = {The Visual Computer (Proc. of Computer Graphics Internatinal 2022)},
      volume    = {38},
      pages     = {3121--3133},
      year      = {2022}
    }</pre>
    </div>
    <hr boader="1">

    <!-- <h3>Acknowledgments</h3>
    The authors would like to thank ZOZO, Inc. for providing a real photograph dataset, without which this work was not possible. The authors would also like to thank the anonymous referees for their constructive comments.
    For our accompanying video, input images courtesy of Z, A, B, and C.
    <hr boader="1"> -->

    <p>Last modified: Jun 2022</p>
    [<a href="javascript:history.back()">back</a>]
  </div>
</BODY>

</HTML>