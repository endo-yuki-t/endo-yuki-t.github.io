<HTML>
<HEAD>
<META http-equiv="content-type" content="text/html; charset=iso-8859-1">
<TITLE>Diversifying Semantic Image Synthesis and Editing via Class- and Layer-wise VAEs</TITLE>
<style type="text/css">
#wrap{
  width:900px;
  margin-right:auto;
  margin-left:auto;
}
#wrap2{
  width:1440px;
  margin-right:auto;
  margin-left:auto;
}
</style>
</HEAD>
<BODY bgcolor="#FFFFFF">
<div id="wrap"><H2 align="center">Diversifying Semantic Image Synthesis and Editing via Class- and Layer-wise VAEs</H2>
</div>
<CENTER>

<P><a href="https://endo-yuki-t.github.io">Yuki Endo</a> and <a href="http://kanamori.cs.tsukuba.ac.jp/index.html">Yoshihiro Kanamori</a></P>
<P>University of Tsukuba</P>
<P>Pacific Graphics 2020</P>
<BR>
<div id="wrap"><img src="teaser.jpg" width="100%" border="0"></div>
</CENTER>

<div id="wrap">
<HR boader="1">
<h3>Abstract:</h3>
<p align="justify">Semantic image synthesis is a process for generating photorealistic images from a single semantic mask. To enrich the diversity of multimodal image synthesis, previous methods have controlled the global appearance of an output image by learning a single latent space. However, a single latent code is often insufficient for capturing various object styles because object appearance depends on multiple factors. To handle individual factors that determine object styles, we propose a class- and layer-wise extension to the variational autoencoder (VAE) framework that allows flexible control over each object class at the local to global levels by learning multiple latent spaces. Furthermore, we demonstrate that our method generates images that are both plausible and more diverse compared to state-of-the-art methods via extensive experiments with real and synthetic datasets in three different domains. We also show that our method enables a wide range of applications in image synthesis and editing tasks.</p>
<p><b>Keywords</b>: Artificial intelligence; Image manipulation </p>

<HR boader="1">
<h3>Video:</h3>
<CENTER>
<iframe width="640" height="360" src="https://www.youtube.com/embed/Ad4kYzUZqT0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</CENTER>
<HR boader="1">

<h3>Code:</h3>
<ul>
  <li><a href="https://github.com/endo-yuki-t/DiversifyingSMIS">PyTorch Code<a></li>
  <li><a href="https://drive.google.com/file/d/13MSBGQgaqREq6prmaZxT4uTYmsn2-RRq/view?usp=sharing">Pre-trained Model<a> (2.7GB)</li>
</ul>

<HR boader="1">
<h3>Publication:</h3>
<ol>
  <li>Yuki Endo, Yoshihiro Kanamori: "Diversifying Semantic Image Synthesis and Editing via Class- and Layer-wise VAEs," Computer Graphics Forum (Proc. of Pacific Graphics 2020), 2020. [<a href="https://arxiv.org/abs/2106.13416">arXiv<a>][<a href="./endo_pg20_lowres.pdf">PDF(lowres)</a> (2MB)][<a href="https://drive.google.com/file/d/1nIH5WIZIJ1XZNZdDF40cWeNhgRtymbmj/view?usp=sharing">Supp</a> (183MB)]
</ol>

<hr boader="1">
<h3>BibTeX Citation</h3>
<div style="padding: 10px; margin-bottom: 10px; border: 1px solid #333333;">
@Article{endoPG2020,<br>
  Title                    = {Diversifying Semantic Image Synthesis and Editing via Class- and Layer-wise VAEs},<br>
  Author                   = {Yuki Endo and Yoshihiro Kanamori},<br>
  Journal                  = {Computer Graphics Forum (Proc. of Pacific Graphics 2020)},<br>
  volume                   = {39},<br>
  number                   = {7},<br>
  pages                    = {519-530},<br>
  doi                      = {10.1111/cgf.14164},<br>
  Year                     = {2020}<br>
}</div>
<hr boader="1">

<p>Last modified: Nov. 2020</p>
[<a href="javascript:history.back()">back</a>]
</div>
</BODY>
</HTML>
