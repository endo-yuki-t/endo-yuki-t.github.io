<!DOCTYPE html>
<html>
<head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#">
<meta charset="UTF-8">
<title>Yuki ENDO</title>
<meta name="description" content="Yuki Endo">
<meta name="viewport" content="width=device-width,initial-scale=1">
<link rel="canonical" href="https://endo-yuki-t.github.io">    
<!-- スタイルシートはここから -->
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
<link rel="stylesheet" href="css/style.css">
</head>

<body data-spy="scroll" data-taget="#navbar">
<div class="navbar">
<div class="container">
  <a href="#sec1">Profile</a>
  <a href="#sec2">Projects</a>
  <a href="#sec3">Publications</a>
  <a href="#sec4">Awards</a>
  <a href="#sec5">Lectures</a>
　<a href="https://endo-yuki-t.github.io/index_ja.html">&#x25B6;Japanese</a>
</div>
</div>


<!--<div class="navbar-box bg-dark">
<div class="bg-dark container">
	<nav class="navbar navbar-expand-md navbar-dark bg-dark">
          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#Navbar" aria-controls="Navbar" aria-expanded="false" aria-label="ナビゲーションの切替">
            <span class="navbar-toggler-icon"></span>
          </button>
          <div class="collapse navbar-collapse" id="Navbar">
            <ul class="navbar-nav text-md-center nav-justified w-100">
            <li class="nav-item"><a class="nav-link" href="#sec1">Profile</a></li>
                <li class="nav-item"><a class="nav-link" href="#sec2">Projects</a></li>
                <li class="nav-item"><a class="nav-link" href="#sec3">Publications</a></li>
                <li class="nav-item"><a class="nav-link" href="#sec4">Awards</a></li>
                <li class="nav-item"><a class="nav-link" href="#sec5">Lectures</a></li>

            </ul>
      </nav>
</div>		
</div>
-->
<br>
<section class="container py-5" id="sec1">
<h2 class="heading d-inline-block mr-2">Profile</h2>
<p><b>Yuki Endo</b><img src="imgs/r1endo.png" align="right" width=128><br>
Ph.D. in Engineering, Assistant Professor<br>
<a href="http://www.cgg.cs.tsukuba.ac.jp/">Computational Geometry and Graphics Laboratory (CGG)</a><br>
Department of Computer Science, <br>
University of Tsukuba</p>
<p>E-mail: endo(AT)cs.tsukuba.ac.jp</p>

<h3 class="h5 mr-2 font-weight-bold">Research Interests:</h3>
Computer graphics, Image editing techniques, Image generative models, Machine learning<br>
<a href="https://scholar.google.co.jp/citations?user=v3k161EAAAAJ&hl=ja">Google Scholar</a>
</section>

<section class="container py-5" id="sec2">
<h2 class="heading d-inline-block mr-2">Selected Projects</h2>
<table border="0">
<tbody>
<tr>
  <td><a href="https://www.cgg.cs.tsukuba.ac.jp/~yoshikawa/pub/style_human_clip/"><img src="https://www.cgg.cs.tsukuba.ac.jp/~endo/web_images/stylehumanclip_thumb.jpg" width="150"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">StyleHumanCLIP: Text-guided Garment Manipulation for StyleGAN-Human (<a href="https://www.cgg.cs.tsukuba.ac.jp/~yoshikawa/pub/style_human_clip/">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="https://www.cgg.cs.tsukuba.ac.jp/~okuyama/pub/diffbody/"><img src="https://www.cgg.cs.tsukuba.ac.jp/~endo/web_images/diffbody_thumb.jpg" width="150"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">DiffBody: Diffusion-based Pose and Shape Editing of Human Images (IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024) (<a href="https://www.cgg.cs.tsukuba.ac.jp/~okuyama/pub/diffbody/">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="projects/MAG/"><img src="projects/MAG/thumb.jpg" width="150"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Masked-Attention Diffusion Guidance for Spatially Controlling Text-to-Image Generation (The Visual Computer, 2023) (<a href="projects/MAG/">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="https://cgg.cs.tsukuba.ac.jp/~itohlee/pub/ADFD/"><img src="https://www.cgg.cs.tsukuba.ac.jp/~endo/web_images/age23_thumb.jpg" width="150"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Age-Dependent Face Diversification via Latent Space Analysis (The Visual Computer, Computer Graphics International 2023) (<a href="https://cgg.cs.tsukuba.ac.jp/~itohlee/pub/ADFD/">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="projects/UserControllableLT/"><img src="projects/UserControllableLT/thumb.gif" width="150"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">User-Controllable Latent Transformer for StyleGAN Image Layout Editing (Pacific Graphics 2022) (<a href="projects/UserControllableLT/">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="projects/StyleGANSparseControl/"><img src="projects/StyleGANSparseControl/thumb5.jpg" width="200"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Controlling StyleGANs Using Rough Scribbles via One-shot Learning (Computer Animation and Virtual Worlds, Computer Graphics International 2022) (<a href="projects/StyleGANSparseControl/">Project</a>)</h3><br>
  <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Few-shot Semantic Image Synthesis Using StyleGAN Prior (<a href="https://arxiv.org/abs/2103.14877">arXiv</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="http://www.cgg.cs.tsukuba.ac.jp/~yoshikawa/pub/sketch_to_diverse_image/"><img src="https://www.cgg.cs.tsukuba.ac.jp/~endo/web_images/yoshikawa_TVCJ2022_thumb.jpg" width="200"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Diversifying Detail and Appearance in Sketch-Based Face Image Synthesis (The Visual Computer, Computer Graphics International 2022) (<a href="http://www.cgg.cs.tsukuba.ac.jp/~yoshikawa/pub/sketch_to_diverse_image/">Project</a>)</h3><br>
  </td>
</tr>
<tr>
<tr>
  <td><a href="http://cgg.cs.tsukuba.ac.jp/~tajima/pub/relighting_in_the_wild/"><img src="https://www.cgg.cs.tsukuba.ac.jp/~endo/web_images/rlh.gif" width="200"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Relighting Humans in the Wild:
Monocular Full-Body Human Relighting with Domain Adaptation (Pacific Graphics 2021)(<a href="http://cgg.cs.tsukuba.ac.jp/~tajima/pub/relighting_in_the_wild/">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="projects/clVAE/"><img src="projects/clVAE/teaser.jpg" width="200"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Diversifying Semantic Image Synthesis and Editing via Class- and Layer-wise VAEs (Pacific Graphics 2020)(<a href="projects/clVAE/">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="projects/AnimatingLandscape/"><img src="projects/AnimatingLandscape/output1.gif" width="200"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Animating Landscape:Self-Supervised Learning of Decoupled Motion and Appearance for Single-Image Video Synthesis (SIGGRAPH ASIA 2019)(<a href="projects/AnimatingLandscape/">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="http://kanamori.cs.tsukuba.ac.jp/projects/relighting_human/"><img src="http://kanamori.cs.tsukuba.ac.jp/projects/relighting_human/teaser.jpg" width="200"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Relighting Humans: Occlusion-Aware Inverse Rendering for Full-Body Human Images (SIGGRAPH ASIA 2018)(<a href="http://kanamori.cs.tsukuba.ac.jp/projects/relighting_human/">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="https://www.cgg.cs.tsukuba.ac.jp/~endo//projects/DrTMO/index.html"><img src="https://www.cgg.cs.tsukuba.ac.jp/~endo//projects/DrTMO/thumb.jpg" width="200"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Deep Reverse Tone Mapping (SIGGRAPH ASIA 2017)(<a href="https://www.cgg.cs.tsukuba.ac.jp/~endo//projects/DrTMO/index.html">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="https://www.cgg.cs.tsukuba.ac.jp/~kikuchi/human_parsing.html"><img src="imgs/pe_model.png" width="200"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Transferring pose and augmenting background for deep human-image parsing and its applications (Computational Visual Media, PG2017 short paper)(<a href="https://www.cgg.cs.tsukuba.ac.jp/~kikuchi/human_parsing.html">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><img src="imgs/dsp.png" width="200"></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Predicting Destinations from Partial Trajectories Using Recurrent Neural Network (PAKDD 2017)[<a href="https://www.cgg.cs.tsukuba.ac.jp/~endo//pdf/pakdd2017_endo_preprint.pdf">PDF (author-created version)</a>]</h3><br>
  </td>
</tr>
<tr>
  <td><a href="projects/deepprop/"><img src="projects/deepprop/thumb.png" width="200"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">DeepProp: Extracting Deep Features from a Single Image for Edit Propagation (Eurographics 2016)(<a href="https://www.cgg.cs.tsukuba.ac.jp/~endo//projects/deepprop/">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="http://iizuka.cs.tsukuba.ac.jp/projects/weathering/weathering_eng.html"><img src="http://iizuka.cs.tsukuba.ac.jp/projects/weathering/images/thumb.png" width="200"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Single Image Weathering via Exemplar Propagation (Eurographics 2016)(<a href="http://iizuka.cs.tsukuba.ac.jp/projects/weathering/weathering_eng.html">Project</a>)</h3><br>
  </td>
</tr>
  <td><img src="imgs/tm.png" width="200"></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Deep Feature Extraction from Trajectories for Transportation Mode Estimation (PAKDD 2016)[<a href="https://www.cgg.cs.tsukuba.ac.jp/~endo//pdf/pakdd2016_endo_preprint.pdf">PDF (author-created version)</a>]</h3><br>
  </td>
</tr>
<tr>
  <td><a href="https://www.cgg.cs.tsukuba.ac.jp/%7Eiizuka/projects/make3D/make3d_eng.html"><img src="imgs/thumb4.jpg" width="200"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Efficient Depth Propagation for Constructing a Layered Depth Image from a Single Image (Pacific Graphics 2014)(<a href="https://www.cgg.cs.tsukuba.ac.jp/%7Eiizuka/projects/make3D/make3d_eng.html">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="https://www.cgg.cs.tsukuba.ac.jp/%7Eiizuka/projects/reposition/repos_eng.html"><img src="imgs/thumb3.jpg" width="200"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Object Repositioning Based on the Perspective in a Single Image  (Computer Graphics Forum) (<a href="https://www.cgg.cs.tsukuba.ac.jp/%7Eiizuka/projects/reposition/repos_eng.html">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="http://kanamori.cs.tsukuba.ac.jp/projects/reflection_matting/"><img src="imgs/other_results.jpg"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Matting and Compositing for Fresnel Reflection on Wavy Surfaces (Eurographics Symposium on Rendering 2012)(<a href="http://kanamori.cs.tsukuba.ac.jp/projects/reflection_matting/">Project</a>)</h3><br>
  </td>
</tr>
<tr>
  <td><a href="https://www.cgg.cs.tsukuba.ac.jp/projects/2011/weathering/"><img src="imgs/thumb_2.jpg"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">Weathering effects with geometric details for images (Computer Graphics International 2011, short paper)(<a href="https://www.cgg.cs.tsukuba.ac.jp/projects/2011/weathering/">Project</a>)[<a href="https://www.cgg.cs.tsukuba.ac.jp/~endo//pdf/cgi2011_endo.pdf">PDF (author-created version)</a>]</h3><br>
  </td>
</tr>
<tr>
  <td><a href="https://www.cgg.cs.tsukuba.ac.jp/projects/2011/popupcard/"><img src="imgs/thumb_1.jpg"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">An Interactive Design System for Pop-Up Cards with a Physical Simulation (Computer Graphics International 2011)(<a href="https://www.cgg.cs.tsukuba.ac.jp/projects/2011/popupcard/">Project</a>)</h3><br></td>
</tr>
<tr>
  <td><a href="https://www.cgg.cs.tsukuba.ac.jp/projects/2010/waterstain/"><img src="imgs/thumb_0.jpg"></a></td>
  <td> <h3 class="h5 d-block d-md-inline-block mt-3 mt-md-0">An Interactive Design System for Water Flow Stains on Outdoor Images (Smart Graphics 2010)<br>
(<a href="https://www.cgg.cs.tsukuba.ac.jp/projects/2010/waterstain/">Project</a>)[<a href="https://www.cgg.cs.tsukuba.ac.jp/~endo//pdf/sg10_endo.pdf">PDF (author-created version)</a>]</h3></td>
</tr>
</tbody></table>
</section>

<section class="container py-5" id="sec3">
<h2 class="heading d-inline-block mr-2">Publications</h2>
<h3 class="h5 mr-2 font-weight-bold">Journals:</h3>
<ol>
	<li><b>Yuki Endo</b>: "Masked-Attention Diffusion Guidance for Spatially Controlling Text-to-Image Generation," The Visual Computer, Nov. 2023. </li>
<li>Taishi Ito, <b>Yuki Endo</b>, Yoshihiro Kanamori: "Age-Dependent Face Diversification via Latent Space Analysis," The Visual Computer (Proc. of Computer Graphics Internatinal 2023), Vol. 39, pp.3221-3233, July 2023. </li>
	<li><b>Yuki Endo</b>: "User-Controllable Latent Transformer for StyleGAN Image Layout Editing," Computer Graphics Forum (Proc. of Pacific Graphics 2022), Vol. 41, Issue 7, pp.395-406, Oct. 2022. (<font color="red">Best Paper Honorable Mention Award</font>)</li>
	<li><b>Yuki Endo</b>, Yoshihiro Kanamori: "Controlling StyleGANs Using Rough Scribbles via One-shot Learning," Computer Animation and Virtual Worlds (Computer Graphics International 2022), Vol. 33, Issue 5, 16 pages, Sep. 2022. </li>
	<li>Haruka Takahashi, Yoshihiro Kanamori, <b>Yuki Endo</b>: "3D terrain estimation from a single landscape image," Computer Animation and Virtual Worlds (Computer Graphics International 2022), 14 pages, Sep. 2022. 
	<li>Takato Yoshikawa, <b>Yuki Endo</b>, Yoshihiro Kanamori: "Diversifying Detail and Appearance in Sketch-Based Face Image Synthesis," The Visual Computer (Computer Graphics International 2022), Vol. 38, Issue 9-10, pp. 3121-3133, Sep. 2022. </li>
        <li>Daichi Tajima, Yoshihiro Kanamori, <b>Yuki Endo</b>: "Relighting Humans in the Wild: Monocular Full-Body Human Relighting with Domain Adaptation," Computer Graphics Forum (Proc. of Pacific Graphics 2021), Vol. 40, No. 7, pp.205-216, 2021</li>
	<li><b>Yuki Endo</b>, Yoshihiro Kanamori: "Diversifying Semantic Image Synthesis and Editing via Class- and Layer-wise VAEs," Computer Graphics Forum (Proc. of Pacific Graphics 2020), Vol.39, Issue 7, pp.519-530, 2020</li>
	<li>Hokuto Tateyama, <b>Yuki Endo</b>, Shigeru Kuriyama, "Optimization of Image Color Conversion for LED Point Light Sources,"  IEICE Transactions on Information and Systems (Japanese Edition), D, Vol.J103-D,No.04, pp.269-279, April 2019.</li>
	<li><b>Yuki Endo</b>, Yoshihiro Kanamori, Shigeru Kuriyama: Animating Landscape: Self-Supervised Learning of Decoupled Motion and Appearance for Single-Image Video Synthesis," ACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2019), Vol. 38, No. 6, Article No. 175, 2019.</li>
        <li>Yoshihiro Kanamori, <b>Yuki Endo</b>: "Relighting Humans: Occlusion-Aware Inverse Rendering for Full-Body Human Images," ACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2018), 37, 6, Article No. 270, November 2018.</li>
	<li>Takazumi Kikuchi, <b>Yuki Endo</b>, Yoshihiro Kanamori, Taisuke Hashimoto, and Jun Mitani, "Transferring pose and augmenting background for deep human-image parsing and its applications," Journal of Computational Visual Media, 12 pages, 2018. [<a href="https://link.springer.com/article/10.1007%2Fs41095-017-0098-0">PDF, Supplemental material</a> (open access)](<font color="red">CVMJ Honorable Mention Award</font>)</li>
        <li>Yan Zhao, <b>Yuki Endo</b>, Yoshihiro Kanamori, Jun Mitani: "Approximating 3D Surfaces using Generalized Waterbomb Tessellations," Journal of Computational Design and Engineering, 2018. (ESCI, Accepted) <a href="https://doi.org/10.1016/j.jcde.2018.01.002">https://doi.org/10.1016/j.jcde.2018.01.002</a></li>
	<li>Shuhei Yamamoto, <b>Yuki Endo</b>, Hiroyuki Toda, "Near-miss Event Detection Method from Drive Record Data Using Video and Sensor Signal," IPSJ Transactions on Databases (in Japanese), 10(4), pp.26-30, December 2017. </li>
	<li><b>Yuki Endo</b>, Yoshihiro Kanamori, Jun Mitani: "Deep Reverse Tone Mapping," ACM Transactions on Graphics (Proc. of SIGGRAPH ASIA 2017), 36, 6, pp.177:1-177:10, November 2017.</li>
	<li>Emi Miyamoto, <b>Yuki Endo</b>, Yoshihiro Kanamori, Jun Mitani: "Semi-Automatic Conversion of 3D Shape into Flat-Foldable Polygonal Model," Computer graphics Forum (Proc. of Pacific Graphics 2017), 10 pages, October 2017. </li>
	<li>Yoshiaki Takimoto, Kyosuke Nishida, <b>Yuki Endo</b>, Hiroyuki Toda, Hiroshi Sawada, and Yoshiharu Ishikawa, "Time-Aware Personalized Destination Prediction," IEICE Transactions on Information and Systems (Japanese Edition), D, Vol. J100-D, No. 4, pp. 472-484, April 2017. </li>
	<li><b>Yuki Endo</b>, Hiroyuki Toda, Kyosuke Nishida, and Jotaro Ikedo: "Classifying spatial trajectories using representation learning," International Journal of Data Science and Analytics, Volume 2, Issue 3, pp.107-117, 2016. </li>
	<li><b>Yuki Endo</b>, Satoshi Iizuka, Yoshihiro Kanamori, and Jun Mitani, "DeepProp: Extracting Deep Features from a Single Image for Edit Propagation," Computer Graphics Forum (Proc. of Eurographics 2016), May 9-13, 2016. </li>
	<li>Satoshi Iizuka, <b>Yuki Endo</b>, Yoshihiro Kanamori, Jun Mitani:"Single Image Weathering via Exemplar Propagation," Computer Graphics Forum (Proc. of Eurographics 2016), May 9-13, 2016. </li>
	<li>Makoto Kawano, <b>Yuki Endo</b>, Hiroyuki Toda, Yoshimasa Koike, Ueda Kazuhiro, "Feature Extraction from Movement Trajectories Using Recursive Autoencoder," DBSJ Japanese Journal, Vol.14, 2016, </li>
    <li><b>Yuki Endo</b>, Hiroyuki Toda, Yoshimasa Koike: "Feature Extraction from GPS logs for Transportation Mode Estimation Using Representation Learning," IPSJ Transactions on Databases (in Japanese), 8(3),12-23, September 30, 2015.</li>
    <li><b>Yuki Endo</b>, Yoshihiro Kanmori, Jun Mitani, Yukio Fukui: "A Design System for Water Flow Stain Images Using Particle Simulation," Journal of Information Processing Society of Japan (in Japanese), Vol.56, No.3, pp.1049-1058, 2015. </li>
    <li>Satoshi, Iizuka, <b>Yuki Endo</b>, Masaki Hirose, Yoshihiro Kanamori, Jun Mitani and Yukio Fukui: "Object Repositioning Based on the Perspective
in a Single Image," Computer Graphics Forum, Volume 33, Issue 8, pages
157-166, Dec. 2014. (presented at EUROGRAPHICS 2015)</li>
	<li>Satoshi, Iizuka, <b>Yuki Endo</b>, Yoshihiro Kanamori, Jun
Mitani and Yukio Fukui: "Efficient Depth Propagation for Constructing a
Layered Depth Image from a Single Image," Computer Graphics Forum (Proc.
 of Pacific Graphics 2014), Volume 33, Issue 7, pages 279-288, Oct.
2014.(acceptance rate: 20%)</li>
    <li><b>Yuki Endo</b>, Yoshihiro Kanamori, Yukio Fukui and Jun Mitani: "Matting and Compositing for Fresnel Reflection on Wavy
Surfaces," Computer Graphics Forum (Proc. of Eurographics Symposium on Rendering 2012), Vol. 31, No. 4, pp. 1435-1443, 2012. (acceptance rate:
30%) [<a href="http://kanamori.cs.tsukuba.ac.jp/projects/reflection_matting/egsr12_endo_reflection.pdf">PDF</a> (2.1MB)] [<a href="http://kanamori.cs.tsukuba.ac.jp/projects/reflection_matting/egsr12_endo_reflection.pptx">PPTX</a> (18.6MB, without movies)] [<a href="http://kanamori.cs.tsukuba.ac.jp/projects/reflection_matting/egsr12_endo_reflection.mp4">Movie</a> (24.4MB)] [<a href="http://kanamori.cs.tsukuba.ac.jp/projects/reflection_matting/BibTex.txt">BibTex</a>]
</li>
    <li>Satoshi Iizuka, <b>Yuki Endo</b>, Jun Mitani, Yoshihiro
Kanamori, Yukio Fukui: "An Interactive Design System for Pop-Up Cards
with a Physical Simulation," The Visual Computer (Proc. of Computer
Graphics International 2011), Volume 27, Issue 6, 605-612, 2011.
(acceptance rate: 16%)</li>
</ol>
<h3 class="h5 mr-2 font-weight-bold">International:</h3>
<ol>
	<li>Xingchao Yang, Takafumi Taketomi, <b>Yuki Endo</b>, Yoshihiro Kanamori, "Makeup Prior Models for 3D Facial Makeup Estimation and Applications," CVPR 2024. [<a href="https://arxiv.org/abs/2403.17761">arXiv</a>][<a href="https://yangxingchao.github.io/makeup-priors-page/">Project</a>]</li>
	<li>Takato Yoshikawa, <b>Yuki Endo</b>, Yoshihiro Kanamori: "StyleHumanCLIP: Text-guided Garment Manipulationfor StyleGAN-Human," International Conference on Compuer Vision Theory and Applications (VISAPP) 2024, Feb. 2024. (<font color="red">Best Student Paper Award</font>)</li>
	<li>Yuta Okuyama, <b>Yuki Endo</b>, Yoshihiro Kanamori: "DiffBody: Diffusion-based Pose and Shape Editing of Human Images," IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024. (to appear) </li>
	<li>Sergey Pavlov, Yoshihiro Kanamori, and <b>Yuki Endo</b>, "Line2Depth: Indoor Depth Estimation from Line Drawings," Proc. of the 16th International Conference on Computer Vision Theory and Applications (VISAPP 2021), Feb. 2021 (short paper). </li>
	<li>Kurei Fujiwara, <b>Yuki Endo</b>, Shieru Kuriyama, "Sketch-based Deep Generative Models Conditioned on a Background Image,"  6th International Conference on Advanced Informatics (ICAICTA2019), 6 pages, Sep. 2019. </li>
        <li>Takumi Yajima, Yoshihiro Kanamori, <b>Yuki Endo</b> and Jun Mitani, "Interactive Edge-Aware Segmentation of Character Illustrations for Articulated 2D Animations," In Proc. of NICOGRAPH International 2018, 8 pages, June 29-30, 2018, Tainan, Taiwan. <font color="red">(Best Paper Award)</font></li>
	<li>Takazumi Kikuchi, <b>Yuki Endo</b>, Yoshihiro Kanamori, Jun Mitani: "Transferring Pose and Augmenting Background Variation for Deep Human Image Parsing," In Proc. of Pacific Graphics 2017, short paper, 6 pages, October 2017. </li>
	<li>Taisuke Hashimoto, Yoshihiro Kanamori, <b>Yuki Endo</b>, Jun Mitani: "Improving Bivariate BRDF Acquisition by Optimizing Light Directions,” In Proc. of Pacific Graphics 2017, poster, 2 pages, October 2017. </li>
	<li>Peng Wang, Yoshihiro Kanamori, Yuki Endo, and Jun Mitani, "Body-shape Transfer for Super Deformation of 3D Character Models," In Proc. of NICOGRAPH International 2017, 7 pages, June 2-3, Kyoto, 2017. <font color="red">(Best Paper Award)</font>
	</li>
	<li><b>Yuki Endo</b>, Kyosuke Nishida, Hiroyuki Toda, and Hiroshi Sawada, "Predicting Destinations from Partial Trajectories Using Recurrent Neural Network," in Proceedings of the 21st Pacific Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2017), pp.160-172, Korea, May 2017. (full paper, 28%), <a href="https://doi.org/10.1007/978-3-319-57454-7_13">https://doi.org/10.1007/978-3-319-57454-7_13</a></li>
	<li>Shinichi Tanaka, <b>Yuki Endo</b>, Yoshihiro Kanamori, Jun Mitani : "A generation method of origami model for CG" , International Conference on Mathematical Modeling and Applications 2016'Origami-Based Modeling and Analysis', Tokyo, Univ. of Meiji, Nov. 9-12, 2016. <font color="red">(Poster Award)</font></li>
	<li><b>Yuki Endo</b>, Hiroyuki Toda, Kyosuke Nishida, Akihisa Kawanobe: "Deep Feature Extraction from Trajectories for Transportation Mode Estimation," In Proc. of PAKDD2016, April 19-2. (long oral presentation, 12.7%), <a href="https://doi.org/10.1007/978-3-319-31750-2_5">https://doi.org/10.1007/978-3-319-31750-2_5</a></li>
	<li><b>Yuki Endo</b>, Hiroyuki Toda, Yoshimasa Koike: "What’s Hot in The Theme: Query Dependent Emerging Topic Extraction from Social
Streams," In Proc. of World Wide Web 2015 Companion, pp.31-32, Florence, May 2015. (acceptance rate: 30%)</li>
    <li><b>Yuki Endo</b>, Yoshihiro Kanamori, Jun Mitani, Yukio Fukui:
"Weathering effects with geometric details for images," In Proc. of
Computer Graphics International 2011, s-24 pp.1-4, 2011-6.</li>
    <li><b>Yuki Endo</b>, Yoshihiro Kanamori, Jun Mitani, Yukio Fukui:
"An Interactive Design System for Water Flow Stains on Outdoor Images,"
In Proc. of smart graphics 2010, 2010-6. <a href="https://doi.org/10.1007/978-3-642-13544-6_16">https://doi.org/10.1007/978-3-642-13544-6_16</a></li>
</ol>
<h3 class="h5 mr-2 font-weight-bold">Domestic:</h3>
<ol>
<li><b>遠藤 結城</b>, "Masked-Attention Diffusion Guidance によるText-to-Image の空間的制御", Visual Computing 2023 ロング発表, 2023-9. (<font color="red">VC論文賞, CGVI優秀研究発表賞</font>)</li>
<li>奥山 裕大, <b>遠藤 結城</b>, 金森 由博 , "拡散モデルを用いた人物画像の姿勢と体型の編集", Visual Computing 2023 ロング発表, 2023-9. (<font color="red">CGVI学生発表賞</font>)</li
<li>楊 興超, 武富 貴史, <b>遠藤 結城</b>, 金森 由博 , "連続的パラメータによる顔画像の化粧制御 ", Visual Computing 2023 ロング発表, 2023-9. </li>
<li>吉川 天斗, <b>遠藤 結城</b>, 金森 由博 , "StyleHumanCLIP：StyleGAN-Humanを用いた人物画像のテキストによる服装操作", Visual Computing 2023 ロング発表, 2023-9. (<font color="red">CGVI学生発表賞</font>)</li>
<li>金井俊樹，<b>遠藤結城</b>，金森由博 , "多段超解像による季節制御可能な大規模地形テクスチャ生成", Visual Computing 2023 ポスター発表, 2023-9. (<font color="red">CGVI学生発表賞</font>)</li>
<li>内田大智，金森由博，<b>遠藤結城</b>, ""画像変形による画像審美性の向上", 情報処理学会第 85 回全国大会, 2023-3. (<font color="red">学生奨励賞</font>) </li>
<li>伊藤泰志，<b>遠藤結城</b>，金森由博, "潜在空間解析による顔画像年齢操作の多様化と精度向上", 情報処理学会第 85 回全国大会, 2023-3. </li>
<li>吉川 天斗，<b>遠藤 結城</b>, 金森由博, "StyleGAN を用いたテキストによる人物画像の服装編集手法", 第 189 回コンピュータグラフィックスとビジュアル情報学研究発表会, 2023-2. (<font color="red">学生発表賞</font>)</li>
<li>田島大地，金森由博，<b>遠藤 結城</b>, "高周波の照明と影を考慮した人物全身画像の再照明", 第 189 回コンピュータグラフィックスとビジュアル情報学研究発表会, 2023-2. </li>
<li>金井 俊樹, <b>遠藤 結城</b>, 金森 由博, "高さマップからの気候や季節で制御可能な地形テクスチャ生成", 第 188 回コンピュータグラフィックスとビジュアル情報学研究発表会, 2022-11. (<font color="red">CGVI 優秀研究発表賞・学生発表賞受賞</font>)</li>
<li><b>遠藤結城</b>, "ユーザ制御可能なLatent Transformer を用いたStyleGAN 画像のレイアウト編集", Visual Computing 2022 ロング発表, 2022-10. (<font color="red">VC論文賞, CGVI優秀研究発表賞</font>)</li>
<li>金井俊樹，<b>遠藤結城</b>，金森由博 , "高さマップからの気候や季節を考慮した地形テクスチャ生成", Visual Computing 2022 ポスター発表, 2022-10. (<font color="red">企業賞 フォーラムエイト</font>)</li>
<li>金森透有，<b>遠藤結城</b>，金森由博, "連続的な感情パラメータの操作による顔画像の表情操作", Visual Computing 2022 ポスター発表, 2022-10. (<font color="red">企業賞 サイバーエージェント</font>)</li>
<li>田島大地，金森由博，<b>遠藤 結城</b>, "高周波の照明と影を考慮した人物全身画像の再照明", Visual Computing 2022 ポスター発表, 2022-10. </li>
<li>奥山 裕大, 金森 由博, <b>遠藤 結城</b>, 三谷 純, "三次元情報を考慮した人物画像の意味的領域分割", 第 185 回コンピュータグラフィックスとビジュアル情報学研究発表会, 2022-03.</li>
<li>金森 透有, 金森 由博, <b>遠藤 結城</b>, 三谷 純, "顔の特徴点を利用した人物顔画像の感情推定", 第 185 回コンピュータグラフィックスとビジュアル情報学研究発表会, 2022-03.</li>
<li>金森由博，銭 庭涵, <b>遠藤 結城</b>, "線画を利用したイラスト顔ランドマークの改良", 第 227 回コンピュータビジョンとイメージメディア研究発表会, 2021-11.</li>
<li>吉川 天斗, <b>遠藤 結城</b>, 金森 由博, 三谷純, "詳細とスタイルを制御可能にしたスケッチからの顔画像生成手法", 第 184 回コンピュータグラフィックスとビジュアル情報学研究発表会, 2021-11. (<font color="red">学生発表賞</font>)</li>
<li>吉川 天斗, <b>遠藤 結城</b>, 金森 由博, "多様性を考慮したスケッチからの画像生成手法", Visual Computing 2021, 2021-9,10 (ポスター).</li>
<li>Tinghan Qian, Yoshihiro Kanamori, <b>Yuki Endo</b>, "Towards Low-Cost Construction of a Large-Scale Anime Facial Landmark Dataset," Visual Computing 2021, 2021-9,10 (ポスター).</li>
<li><b>遠藤 結城</b>, 金森 由博, "StyleGAN Prior を用いたFew-shot 意味的画像合成", Visual Computing 2021, 2021-9,10.(<font color="red">CGVI 優秀研究発表賞受賞)</font></li>
<li>田島 大地, 金森 由博, <b>遠藤 結城</b>, "実写ドメインに適応した人物全身動画像の再照明", Visual Computing 2021, 2021-9,10.(<font color="red">学生発表賞受賞</font>)</li>
<li>高橋 遼, <b>遠藤 結城</b>, 金森 由博, 三谷 純, "単視点地形景観画像からの3D地形モデルの2段階推定", 第 181 回コンピュータグラフィックスとビジュアル情報学研究発表会, 2021-02.(<font color="red">CGVI 優秀研究発表賞受賞)</font></li>
<li>宇内 智哉, <b>遠藤 結城</b>, 金森 由博, "水面での屈折映像からの歪み除去", Visual Computing 2020, 2020-12 (ポスター).</li>
<li>高橋 遼, <b>遠藤 結城</b>, 金森 由博, "単視点地形景観画像からの地形3Dモデル推定", Visual Computing 2020, 2020-12 (ポスター). (<font color="red">CGVI 優秀研究発表賞受賞</font>)</li>
<li>Sergey Pavlov, Yoshihiro Kanamori, Yuki Endo, "Estimating Depth from Indoor Line Drawings", Visual Computing 2020, 2020-12 (short paper).</li>
<li>金森 由博, 松田 祐紫, <b>遠藤 結城</b>, "カラーイラストからの微分可能評価指標を用いた線画抽出", 第 223 回コンピュータビジョンとイメージメディア研究発表会, 2020-11.(<font color="red">CGVI 優秀研究発表賞受賞</font>)</li>
<li>山口 智史, 金森 由博, <b>遠藤 結城</b>, 三谷 純, "商品画像のための画像クラスを考慮した前景抽出", 第 180 回コンピュータグラフィックスとビジュアル情報学研究発表会, 2020-11.</li>
<li>田島 大地, 金森 由博, <b>遠藤 結城</b>, 三谷 純 , "非拡散反射成分を考慮した人物全身画像の再照明", 第 180 回コンピュータグラフィックスとビジュアル情報学研究発表会, 2020-11.(<font color="red">CGVI 優秀研究発表賞受賞</font>)</li>
<li>松田 祐紫、金森 由博、<b>遠藤 結城</b>, "非顕著な線を重視したカラーイラストからの線画抽出", 第 179 回コンピュータグラフィックスとビジュアル情報学研究発表会, 2020-09.</li>
<li>幸家 大和, <b>遠藤 結城</b>, 栗山 繁 , "UkiyoGAN: 自然画像の浮世絵風スタイル変換", 第 178 回コンピュータグラフィックスとビジュアル情報学研究発表会, 2020-6.(<font color="red">CGVI 優秀研究発表賞受賞</font>)</li>
<li>金森 由博, <b>遠藤 結城</b>, 山口 智史, 三谷 純, "多視点投影を利用した人物3Dモデルの意味的領域分割," Visual Computing 2019, 2019/6/27-29. (口頭発表) (<font color="red">企業賞 (CyberAgent 賞) 受賞</font>)</li>
<li>高筒飛輝, <b>遠藤結城</b>, 栗山繁, "漢字フォント画像からの刺繍データの自動生成," 第18回情報科学技術フォーラム(FIT2019), 2 pages, 2019/9/3-5.</li>
<li>木佐省吾, <b>遠藤結城</b>, 栗山繁, "人の関節回転角系列からの身体中心位置の推定," 第18回情報科学技術フォーラム(FIT2019), 2 pages, 2019/9/3-5.</li>
<li>出口風人, <b>遠藤結城</b>, 栗山繁, "RNNを用いたデータ駆動型モーションリターゲット," 第18回情報科学技術フォーラム(FIT2019), 2 pages, 2019/9/3-5.</li>
<li>鬼塚慎吾, <b>遠藤結城</b>, 栗山繁, "流れ場に基づくワーピングによる深層生成モデルを用いた人物動画生成," 第18回情報科学技術フォーラム(FIT2019), 2 pages, 2019/9/3-5.</li>
<li>高筒飛輝, <b>遠藤結城</b>, 栗山繁, "漢字画像の刺繍データ化のための筆画分解," Visual Computing 2019, 2019/6/27-29. (ポスター発表)</li>
<li>藤原玖嶺, <b>遠藤結城</b>, 栗山繁, "敵対的生成ネットワークを使用したスケッチからの画像生成," Visual Computing 2019, 2019/6/27-29. (ポスター発表)</li>
<li>木佐省吾, <b>遠藤結城</b>, 栗山繁, "人の姿勢系列情報からの身体中心位置の推定," Visual Computing 2019, 2019/6/27-29. (ポスター発表)</li>
<li>鬼塚慎吾, <b>遠藤結城</b>, 栗山繁, "流れ場生成モデルを用いたワーピングによる人物動画生成," Visual Computing 2019, 2019/6/27-29. (ポスター発表)</li>
<li>渡辺光輝, <b>遠藤 結城</b>, 栗山 繁, "イルミネーションでの表示に適した画像ダウンスケーリング手法の比較調査", 2019年電子情報通信学会総合大会, D-11-10, 1 page, Mar. 2019. </li>
	<li><b>遠藤 結城</b>, 金森 由博, 栗山繁, "色と動き情報の学習による静止画像からのシネマグラフ生成," CVIM・CGVI・DCC 合同研究会（CVIM第214回・CGVI第172回・DCC第20回), 2018-11. (<font color="red">CVIM 奨励賞およびCGVI 優秀研究発表賞受賞</font>)</li>
        <li>金森 由博, 遠藤 結城, "人物の単視点全身画像の再照明," Visual Computing 2018, 2018/6/21-23. (口頭発表) (<font color="red">優秀研究発表賞受賞</font>)</li>
	<li>昆将太郎，金森由博，<b>遠藤結城</b>，三谷　純: "線画イラストにおけるカーネルSVMを用いた閉領域の奥行き推定", 情報処理学会第80回全国大会, 2 pages, 2018. </li>
	<li>谷島拓実，金森由博，<b>遠藤結城</b>，三谷　純: "エッジ強調に基づくイラスト画像のための対話的領域分割", 情報処理学会第80回全国大会, 2 pages, 2018. </li>
	<li>山本修平, <b>遠藤 結城</b>, 戸田 浩之: "映像とセンサを用いたドライブレコーダデータからのヒヤリハット検出手法", 第11回 Webとデータベースに関するフォーラム(WebDB Forum 2017), 5 pages, September 2017. </li>
	<li><b>遠藤 結城</b>，西田 京介，戸田 浩之，澤田 宏: "長期的な状態依存性を考慮した移動軌跡からの目的地予測", 第84回MBL研究会 山下記念研究賞奨励講演, abstract, 1 page, August 2017. </li>
	<li>菊池 敬済, <b>遠藤 結城</b>, 金森 由博, 橋本 泰輔, 三谷 純: "ポーズ情報の考慮と背景データの拡張によるCNNを用いた人物画像の意味的領域分割", Visual Computing/グラフィクスとCAD合同シンポジウム 2017, 8 pages, June 2017. </li>
	<li>田中 慎一, <b>遠藤 結城</b>, 金森 由博, 三谷 純: "簡略化モデルによる折紙形状構築手法", Visual Computing/グラフィクスとCAD合同シンポジウム 2017, 6 pages, June 2017.</li>
	<li>宮本 惠未, <b>遠藤 結城</b>, 金森 由博, 三谷 純, "3次元形状を折りたたみ可能な立体へ自動変換する手法の提案," Visual Computing／グラフィクスと CAD 合同シンポジウム 2017, 2017/6/23-24. (ポスター発表) </li>
	<li>橋本 泰輔, 金森 由博, <b>遠藤 結城</b>, 三谷 純, "光源配置の最適化による2変数BRDF測定の改良," Visual Computing／グラフィクスと CAD 合同シンポジウム 2017, 2017/6/23-24. (ポスター発表) </li>
	<li>橋本 泰輔, 金森 由博, <b>遠藤 結城</b>, 三谷 純, "光源配置の最適化による2変数BRDF測定の改良", 映像情報メディア学会, 2017-3-14.  (<font color="red">優秀研究発表賞</font>)</li>
	<li>田中慎一, <b>遠藤結城</b>, 金森由博, 三谷純, "折紙のCG用幾何モデルの生成手法", 日本図学会春季大会, 2016年11月26,27日</li>
	<li>上村紳一郎, <b>遠藤結城</b>, 金森由博, 三谷純, "帯状三次元座標取得装置を用いた曲線折り形状の対話的な生成インタフェースの開発", 日本図学会春季大会, 2016年11月26,27日</li>
	<li><b>遠藤 結城</b>, 西田京介, 戸田浩之, 澤田宏: "長期的な状態依存性を考慮した移動軌跡からの目的地予測"，マルチメディア, 分散, 協調とモバイル(DICOMO2016)シンポジウム, 7G-4, pp. 1524 - 1536, July 2016. (<font color="red">優秀論文賞, 山下記念研究賞</font>)</li>
	<li>瀧本祥章, 西田京介, <b>遠藤 結城</b>, 戸田浩之, 澤田宏, 石川佳治: "時間帯を考慮したパーソナライズ目的地予測"，第8回データ工学と情報マネジメントに関するフォーラム", H1-2, March 2016．(<font color="red">優秀論文賞</font>)</li>
	<li>飯塚里志,　<b>遠藤結城</b>,　金森由博,　三谷純, "物体表面のテクスチャ変化を伴う画像の経年変化の再現",
Visual Computing/グラフィクスとCAD合同シンポジウム 2015, 2015-6. </li>
	<li>河野 慎, <b>遠藤 結城</b>, 戸田浩之, 小池 義昌, 植田 一博: "Recursive Autoencoderにもとづいた移動軌跡からの特徴量自動抽出手法の提案", 第7回データ工学と情報マネジメントに関するフォーラム (DEIM 2015), D5-5, 2015年3月2日～3月4日. (<font color="red">学生プレゼンテーション賞</font>)</li>
	<li><b>遠藤結城</b>, 数原良彦,　戸田浩之, 小池 義昌: "移動手段判定のための表現学習を用いたGPS軌跡からの特徴抽出 ", WebDB Forum 2014, 2014-11. (<font color="red">優秀論文賞, 山下記念研究賞</font>)</li>
	<li><b>遠藤 結城</b>，戸田浩之，鷲崎誠司: "時系列テキストにおけるクエリ依存の局所的なEmerging Topic の抽出", 第6回データ工学と情報マネジメントに関するフォーラム (DEIM 2014), C4-3, 2014年3月3日～3月5日.</li>
    <li>飯塚里志, <b>遠藤結城</b>, 金森由博, 三谷純, 福井幸男: "スクリブルを用いた1枚の画像からの対話的なレイヤ状3次元モデルの生成", Visual Computing/グラフィクスとCAD合同シンポジウム 2013, 2013-6. (<font color="red">GCAD賞</font>)</li>
    <li>飯塚里志, <b>遠藤結城</b>, 金森由博, 三谷純, 福井幸男: "シーンの奥行きを考慮した景観画像における対話的なオブジェクト再配置", Visual Computing/グラフィクスとCAD合同シンポジウム 2012, 2012-6.</li>
    <li><b>遠藤 結城</b>，金森 由博，三谷 純，福井 幸男: "画像における映り込みのマッティングと合成", 第146回グラフィクスとCAD研究会, 2012-2. (<font color="red">GCAD賞, 山下記念研究賞</font>)</li>
    <li>飯塚里志, <b>遠藤結城</b>, 金森由博, 三谷純, 福井幸男: "3次元構造を考慮した対話的な景観画像編集システム",
ソリューション型研究開発プロジェクト2011年度研究成果報告（CS Technical Reports Special Issue on
"Program for Develpment of ICT Solution Architects"）, 2012-2. (<font color="red">ソリューション型研究開発/特別プロジェクト優秀賞 </font>)</li>
    <li>飯塚里志, <b>遠藤結城</b>, 三谷純, 金森由博, 福井幸男: "物理シミュレーションを用いたポップアップカード設計支援システム", Visual Computing/グラフィクスとCAD合同シンポジウム2011, 2011-6. (<font color="red">GCAD賞</font>)</li>
    <li>飯塚里志, <b>遠藤結城</b>: "バネマスモデルを用いたポップアップカード設計支援ツールの開発",
ソリューション型研究開発プロジェクト2010年度研究成果報告（CS Technical Reports Special Issue on
"Program for Develpment of ICT Solution Architects"）, 2011-2. (<font color="red">専攻長表彰</font>) </li>
    <li><b>遠藤 結城</b>，金森 由博，三谷 純，福井 幸男: "アピアランスマップを用いた景観画像のための対話的な経年変化編集システム", 第139回グラフィクスとCAD研究会, 2010-7. (<font color="red">GCAD賞</font>)</li>
    <li><b>遠藤 結城</b>，金森 由博，三谷 純，福井 幸男: "粒子シミュレーションによる水汚れ画像生成システム", Visual Computing/グラフィクスとCAD合同シンポジウム2010, 2010-6. (<font color="red">GCAD賞</font>)</li>
    <li><b>遠藤 結城</b>, 金森 由博, 三谷 純, 福井 幸男: "粒子シミュレーションによる水汚れ画像生成システム", NICOGRAPH 2010 春季大会, 2010-3. </li>
</ol>

<h3 class="h5 mr-2 font-weight-bold">Patents:</h3>
<ol>
<li><b>遠藤結城</b> , 西田京介 , 戸田浩之 , 澤田宏 , 登録番号：6543215号, “目的地予測装置、目的地予測方法、及び目的地予測プログラム”, 登録日: 2019/06/21. </li>
<li>西田京介 , <b>遠藤結城</b> , 戸田浩之 , 川野辺彰久 , 登録番号：6543180号, “目的地予測装置、方法、及びプログラム”, 登録日: 2019/06/21. </li>
<li><b>遠藤結城</b> , 戸田浩之 , 甲谷優, 登録番号：6529470号, “移動状況学習装置、移動状況認識装置、方法、及びプログラム”, 登録日: 2019/05/24. </li>
<li><b>遠藤結城</b> , 西田京介 , 戸田浩之 , 近藤雅芳 , 川野辺彰久 , 登録番号：6521835号, “移動経路予測装置、移動経路予測方法、及び移動経路予測プログラム”, 登録日: 2019/05/10. </li>
<li>松元崇裕, 足利えりか, <b>遠藤結城</b>, 巻口誉宗, 登録番号：6473048号, “移動装置操作端末、移動装置操作方法及び移動装置操作プログラム”, 登録日: 2019/02/01. </li>
<li>足利えりか, 松元崇裕, <b>遠藤結城</b>, 巻口誉宗, 登録番号：6470112号, “移動装置操作端末、移動装置操作方法及び移動装置操作プログラム”, 登録日：2019/01/25. </li>
<li><b>遠藤結城</b>, 戸田浩之, 西田京介, 近藤雅芳, 川野辺彰久, 登録番号：6433877号 “目的地予測装置、目的地予測方法、及び目的地予測プログラム”, 登録日：2018/11/16. </li>
<li>中辻真, 小池義昌, 戸田浩之, <b>遠藤結城</b>
, 片岡泰之, 登録番号：6386931号 “多次元データの予測装置、多次元データの予測方法、多次元データの予測プログラム”, 登録日：2016/08/17.  </li>
<li>松元崇裕, 足利えりか, <b>遠藤結城</b>
, 巻口誉宗, ,登録番号：6382772号, “視線誘導装置、視線誘導方法、および視線誘導プログラム”, 登録日：2018/08/10. </li>
<li>足利えりか, 松元崇裕, <b>遠藤結城</b>, 巻口誉宗, 登録番号：6367759号, “表示画像ズーム端末、表示画像ズーム方法及び表示画像ズームプログラム”, 登録日：2018/07/13.</li>
<li><b>遠藤結城</b>
, 戸田浩之, 小池義昌, 登録番号：6360000号, “移動手段推定モデル生成装置、移動手段推定モデル生成方法、移動手段推定モデル生成プログラム”, 登録日：2018/06/29. </li>
<li>伊藤淳, <b>遠藤結城</b>, 戸田浩之, 小池義昌, 登録番号：6285341号, “スニペット生成装置、スニペット生成方法及びスニペット生成プログラム”, 登録日：2018/02/09.  </li>
<li>中辻真, 小池義昌, 井上孝史, 戸田浩之, <b>遠藤結城</b>
, 登録番号：6276722号, “行動予測装置、行動予測方法及び行動予測プログラム”, 登録日：2018/01/19. </li>
<li><b>遠藤結城</b>, 戸田浩之, 小池義昌, 登録番号：6204261号, “トピックモデリング装置、トピックモデリング方法及びトピックモデリングプログラム”, 登録日：2017/09/18. </li>
<li><b>遠藤結城</b>, 戸田浩之, 小池義昌, 登録番号：6149024号, “移動手段推定モデル生成装置、移動手段推定モデル生成方法、移動手段推定モデル生成プログラム”, 登録日: 2017/05/26. </li>
<li><b>遠藤結城</b>, 戸田浩之, 鷲崎誠司, 登録番号：6091448号 “トピックモデリング装置、トピックモデリング方法、トピックモデリングプログラム”, 登録日: 2017/02/17.  </li>
<li><b>遠藤結城</b>, 戸田浩之, 鷲崎誠司, 登録番号：6042790号, “トレンド分析装置、トレンド分析方法およびトレンド分析プログラム”, 登録日: 2016/11/18. </li>
<li><b>遠藤結城</b>, 数原良彦, 戸田浩之, 小池義昌, 登録番号：6038857号, “移動手段推定モデル生成装置、移動手段推定モデル生成方法、移動手段推定モデル生成プログラム”, 登録日: 2016/11/11. 
<li><b>遠藤結城</b>, 戸田浩之, 佐藤隆, 鷲崎誠司, 登録番号：6040137号, “アイテム推薦装置、アイテム推薦方法およびアイテム推薦プログラム”, 登録日: 2016/11/11. </li>
<li><b>遠藤結城</b>, 佐藤隆, 鷲崎誠司, 登録番号：5952241号, “情報付与装置、情報付与方法および情報付与プログラム”, 登録日: 2016/06/17. </li>
</ol>

<h3 class="h5 mr-2 font-weight-bold">Theses:</h3>
<ol>
	<li>博士論文: "Interactive Image Editing Methods for Reproducing Real-World Appearance Variations", 2017年3月. [<a href="https://www.cgg.cs.tsukuba.ac.jp/thesis/2016/thesis2016d_endo.pdf">PDF</a> (100MB)]</li>
	<li>修士論文: "画像における映り込みのマッティングと合成", 2012年3月. </li>
	<li>卒業論文: "粒子シミュレーションによる水汚れ画像生成システム", 2010年3月. </li>
</ol>
<h3 class="h5 mr-2 font-weight-bold">Grants:</h3>
代表
<ol>
	<li>科学研究費補助金 (基盤研究(C) , 課題番号 23K11143  ), "深層画像生成モデルのユーザ制御の研究", 2023-2025. </li>
        <li>科学研究費補助金 (若手研究, 課題番号 20K19816 ), "限られた教師データを用いた意味的画像合成モデルの開発", 2020-2022. </li>
	<li>科学研究費補助金 (若手研究 (B), 課題番号 17K12689), "ディープニューラルネットワークによる静止画像からの動画像生成手法の開発", 2017-2019. </li>
	<li>公益法人NEC C&C財団 2016年度国際会議論文発表者助成</li>
</ol>
分担
<ol>
	<li>科学研究費補助金 (基盤研究 (B), 課題番号 22H03606), "実写ドメインに適応した光学的要素分解", 2022-2026, 代表者: 金森 由博. </li>
	<li>科学研究費補助金 (基盤研究 (B), 課題番号 19H04231), "アバターを介した非言語コミュニケーションのための動作スタイルの学習と即時変換", 2019-2020, 代表者: 栗山 繁. </li>
	<li>科学研究費補助金 (基盤研究 (B), 課題番号 19H04130), "単視点画像の根源的光学要素分解", 2019-2022, 代表者: 金森 由博. </li>
</ol>

<h3 class="h5 mr-2 font-weight-bold">Invited talks:</h3>
<ol>
	<li>遠藤 結城, "画像生成AIの最前線", Visual Computing 2023 チュートリアル. </li>
	<li>Yuki Endo, "Exploring "WOW!" with Single Images," <a href="http://www.asiagraphics.org/webinar/#session14">Asiagraphics Web Seminar</a>, 2022-09.</li>
	<li>遠藤 結城, "色と動き情報の自己教師あり学習による景観画像からのアニメーション生成", 第19回情報科学技術フォーラム(FIT2020) トップコンファレンスセッション, 2020-09.</li>
	<li>金森 由博, 遠藤 結城, "Relighting Humans: 人物全身画像の遮蔽を考慮した逆レンダリング", Visual Computing 2019 SIGGRAPH ASIA 2018 / Eurographics2019 採択論文 招待講演, 2019-06.</li>
	<li>遠藤 結城, 金森 由博, 三谷 純, "Deep Reverse Tone Mapping", Visual Computing 2018 国際会議 / SIGGRAPH Asia 2017 採択論文 招待講演, 2018-06.</li>
	<li>宮本 惠未, 遠藤 結城, 金森 由博, 三谷 純, "3次元形状を折りたたみ可能な立体へ半自動変換する手法の提案", Visual Computing 2018 国際会議 / SIGGRAPH Asia 2017 採択論文 招待講演, 2018-06.</li>
	<li>茨城県高等学校教育研究会情報部 平成30年度春季研究協議会, "人工知能の最先端とCG・画像処理への応用研究", 2018/6/1, 土浦（県南生涯学習センター）.</li>
</ol>

<h3 class="h5 mr-2 font-weight-bold">Press:</h3>
<ol>
    <li>日経産業新聞第5面, "AIで風景画像を動画に", 2019/11/14</li>
    <li>豊橋技術科学大学、筑波大学、共同プレスリリース, 2019/11/5[<a href="https://www.tut.ac.jp/docs/PR191105.pdf">Link</a>]</li>
    <li>日経新聞その他, "人工知能(AI)を活用した危険運転の自動検出に成功", 2016/9/26.</li>
    <li>日刊工業新聞社, "筑波大、水面の映り込みを自動再現できる画像編集ソフト開発", 2012/05/31.</li>
    <li>日刊工業新聞社, "開くと飛び出すカード ‐ 初心者でも簡単作成", 2011/5/26.</li>
</ol>

<h3 class="h5 mr-2 font-weight-bold">Other Activities:</h3>
<ol>
	<li>遠藤 結城, 第5回 筑波大学産学連携シンポジウム, ポスター発表 "ユーザ制御可能な画像生成AIの研究", 2023-10. </li>
	<li>遠藤 結城, J-WAVE Innovation World Festa Talk Session, "拡張するアニメ：テクノロジーの先に広がる可能性", 2023-10. </li>
</ol>
</section>

<section class="container py-5" id="sec4">
<h2 class="heading d-inline-block mr-2">Awards</h2>
<h3 class="h5 mr-2 font-weight-bold">Awards(自身の受賞):</h3>
<ol>    
	<li>2024年2月, Best Student Paper Award, VISAPP 2024</li>
	<li>2023年9月, VC Young Researcher Award, Visual Computing 2023</li>
	<li>2023年9月, CGVI 優秀研究発表賞, Visual Computing 2023, "Masked-Attention Diffusion Guidance によるText-to-Image の空間的制御"</li>
	<li>2023年9月, VC論文賞, Visual Computing 2023, Masked-Attention Diffusion Guidance によるText-to-Image の空間的制御"</li>
	<li>2022年10月, Best Paper Honorable Mention Award, Pacific Graphics 2022, "User-Controllable Latent Transformer for StyleGAN Image Layout Editing"</li>
	<li>2022年10月, VC論文賞, Visual Computing 2022, "ユーザ制御可能なLatent Transformer を用いたStyleGAN 画像のレイアウト編集"</li>
	<li>2022年10月, CGVI 優秀研究発表賞, Visual Computing 2022, "ユーザ制御可能なLatent Transformer を用いたStyleGAN 画像のレイアウト編集"</li>
	<li>2021年10月, CGVI 優秀研究発表賞, VC2021, "StyleGAN Prior を用いたFew-shot 意味的画像合成"</li>
	<li>2020年3月, 山下記念研究賞, 情報処理学会 (CVIM研究会), "色と動き情報の学習による静止画像からのシネマグラフ生成"</li>
	<li>2019年3月, Honorable mention award, Journal of Computational Visual Media, "Transferring pose and augmenting background for deep human-image parsing and its applications"</li>
	<li>2018年11月, CGVI 優秀研究発表賞, CVIM・CGVI・DCC 合同研究会（CVIM第214回・CGVI第172回・DCC第20回), "色と動き情報の学習による静止画像からのシネマグラフ生成"</li>
	<li>2018年11月, CVIM 奨励賞, CVIM・CGVI・DCC 合同研究会（CVIM第214回・CGVI第172回・DCC第20回), "色と動き情報の学習による静止画像からのシネマグラフ生成"</li>
	<li>2018年3月, 山下記念研究賞, 情報処理学会 (MBL研究会, DICOMO2016), "長期的な状態依存性を考慮した移動軌跡からの目的地予測"</li>
	<li>2017年7月, 研究会推薦博士論文, 情報処理学会, "Interactive Image Editing Methods for Reproducing Real-World Appearance Variations"</li>
	<li>2016年7月, 優秀論文賞, マルチメディア、分散、協調とモバイル(DICOMO2016)シンポジウム, "長期的な状態依存性を考慮した移動軌跡からの目的地予測"</li>
	<li>2016年3月, 山下記念研究賞, 情報処理学会(DBS研究会, 第8 回Web とデータベースに関するフォーラム), "移動手段判定のための表現学習を用いたGPS軌跡からの特徴抽出"</li>
	<li>2015年12月, 総研所長表彰 研究開発奨励賞, NTT サービスイノベーション総合研究所, "空間行動理解技術に関する研究開発"</li>
	<li>2015年10月, 最優秀賞, 国土交通省政策統括官付主催歩行者移動支援アイデアソン・ハッカソン, "あなたのためのルート検索, チームえぼりゅーしょん"</li>
	<li>2014年11月, 優秀論文賞, 第8 回Web とデータベースに関するフォーラム(WebDB Forum 2014）, "移動手段判定のための表現学習を用いたGPS軌跡からの特徴抽出"</li>
	<li>2013年3月, 山下記念研究賞, 情報処理学会(GCAD研究会, 第146 回グラフィクスとCAD 研究会), "画像における映り込みのマッティングと合成"</li>
	<li>2012年2月, 優秀研究発表賞, 第146 回グラフィクスとCAD 研究会, "画像における映り込みのマッティングと合成"</li>
	<li>2010年7月, 優秀研究発表賞, 第139 回グラフィクスとCAD 研究会, "アピアランスマップを用いた景観画像のための対話的な経年変化編集システム"</li>
	<li>2010年6月, 優秀研究発表賞, Visual Computing/グラフィクスとCAD 合同シンポジウム2010, "粒子シミュレーションによる水汚れ画像生成システム"</li>
</ol>

<h3 class="h5 mr-2 font-weight-bold">Awards(共著者の受賞):</h3>
<ol>
	<li>2024年3月, 学生奨励賞, 情報処理学会第86回全国大会, "フォントスタイルを指定可能なテキストからの画像生成"</li>
	<li>2023年9月, 学生発表賞, Visual Computing 2023, "拡散モデルを用いた人物画像の姿勢と体型の編集"</li>
	<li>2023年9月, 学生発表賞, Visual Computing 2023, "StyleHumanCLIP：StyleGAN-Humanを用いた人物画像のテキストによる服装操作"</li>
	<li>2023年9月, 学生発表賞, Visual Computing 2023, "多段超解像による季節制御可能な大規模地形テクスチャ生成"</li>
	<li>2023年3月, 学生奨励賞, 情報処理学会第 85 回全国大会, "画像変形による画像審美性の向上"</li>
	<li>2023年2月, 学生発表賞, 第189回CGVI研究会, "StyleGAN を用いたテキストによる人物画像の服装編集手法"</li>
	<li>2022年11月, CGVI 優秀研究発表, 第188回CGVI研究会, "高さマップからの気候や季節を考慮した地形テクスチャ生成"</li>
	<li>2022年11月, CGVI 学生発表賞, 第188回CGVI研究会, "高さマップからの気候や季節を考慮した地形テクスチャ生成"</li>
	<li>2022年10月, 企業賞 フォーラムエイト, Visual Computing 2022, "高さマップからの気候や季節を考慮した地形テクスチャ生成"</li>
	<li>2022年10月, 企業賞 サイバーエージェント, Visual Computing 2022, "連続的な感情パラメータの操作による顔画像の表情操作"</li>
	<li>2021年11月, 学生発表賞, 第184回CGVI研究会, "詳細とスタイルを制御可能にしたスケッチからの顔画像生成手法". </li>
	<li>2021年10月, 学生発表賞, VC2021, "実写ドメインに適応した人物全身動画像の再照明". </li>
    <li>2021年2月, 優秀研究発表賞, 第181回CGVI研究会, "単視点地形景観画像からの地形3Dモデルの2段階推定"</li>
    <li>2020年12月, 優秀研究発表賞, Visual Computing 2020, "単視点地形景観画像からの地形3Dモデル推定"</li>
    <li>2020年11月, 優秀研究発表賞, 第180回CG・第26回DCC・第223回CVIM合同研究発表会 "カラーイラストからの微分可能評価指標を用いた線画抽出"</li>
    <li>2020年11月, 優秀研究発表賞, 第180回CG・第26回DCC・第223回CVIM合同研究発表会 "非拡散反射成分を考慮した人物全身画像の再照明"</li>
    <li>2020年6月, 優秀研究発表賞, 第178回CGVI研究会, "UkiyoGAN: 自然画像の浮世絵風スタイル変換"</li>
    <li>2020年3月, 山下記念研究賞, 情報処理学会 (Visual Computing 2018), "人物の単視点全身画像の再照明"</li>
    <!--li>2019年12月 豊橋技術科学大学卒業研究発表会, 最優秀発表賞, "UkiyoGAN：自然画像から浮世絵へのスタイル変換". </li-->
    <li>2019年6月, 企業賞 (CyberAgent 賞), Visual Computing 2019, "多視点投影を利用した人物3Dモデルの意味的領域分割"</li>
    <li>2018年6月, 優秀研究発表賞, Visual Computing 2018, "人物の単視点全身画像の再照明"</li>
    <li>2018年6月, Best Paper Award, NICOGRAPH International 2018, "Interactive Edge-Aware Segmentation of Character Illustrations for Articulated 2D Animations"</li>
    <li>2017年6月, Best Paper Award, NICOGRAPH International 2017, "Body-shape Transfer for Super Deformation of 3D Character Models"</li>
    <li>2017年3月, 優秀研究発表賞, 映像情報メディア学会, "光源配置の最適化による2変数BRDF測定の改良"</li>
    <li>2016年11月, Poster Award, International Conference on Mathematical Modeling and Applications 2016 'Origami-Based Modeling and Analysis', "A generation method of origami model for CG"</li>
	<li>2016年5月, 優秀論文賞, DEIM フォーラム2016, "時間帯を考慮したパーソナライズ目的地予測" </li>
	<li>2015年3月, 学生プレゼンテーション賞, DEIM フォーラム2015, "Recursive Autoencoderにもとづいた移動軌跡からの特徴量自動抽出手法の提案"</li>
	<li>2013年6月, 優秀研究発表賞, Visual Computing/グラフィクスとCAD 合同シンポジウム2013, "スクリブルを用いた1枚の画像からの対話的なレイヤ状3次元モデルの生成"</li>
	<li>2011年6月, 優秀研究発表賞, Visual Computing/グラフィクスとCAD 合同シンポジウム2011, "物理シミュレーションを用いたポップアップカード設計支援システム"</li>
</ol>
</section>

<section class="container py-5" id="sec5">
<h2 class="heading d-inline-block mr-2">Lectures</h2>
<h3 class="h5 mr-2 font-weight-bold">2023年度</h3>
<ol>	
	<li>コンピュータグラフィックス基礎 (CG 基礎) (分担, 秋学期 AB, 火34)</li>
	<li>アドバンストCG (分担, 秋学期 AB, 木34)</li>
	<li>データサイエンス (総学第3類CD班、秋学期 AB, 月56)</li>
	<li><a href="http://kanamori.cs.tsukuba.ac.jp/dl_jikken">情報メディア創成学類: 情報メディア実験 B・情報科学類: 知能情報メディア実験</a></li>
	<li>人工知能 (オムニバス講義一回分、秋学期 AB, 11/21(火)4限) 
</ol>
<h3 class="h5 mr-2 font-weight-bold">2022年度</h3>
<ol>	
	<li>コンピュータグラフィクス特論 (分担, 春学期 AB, 木12)</li>
	<li>コンピュータグラフィックス基礎 (CG 基礎) (分担, 秋学期 AB, 火34)</li>
	<li>アドバンストCG (分担, 秋学期 AB, 木34)</li>
	<li>データサイエンス (総学第3類DE班、秋学期 AB, 月56)</li>
	<li><a href="http://kanamori.cs.tsukuba.ac.jp/dl_jikken">情報メディア創成学類: 情報メディア実験 B・情報科学類: 知能情報メディア実験</a></li>
	<li>人工知能 (オムニバス講義一回分、秋学期 AB, 11/22(火)4限) 
</ol>
<h3 class="h5 mr-2 font-weight-bold">2021年度</h3>
<ol>
	<li>コンピュータグラフィックス基礎 (CG 基礎) (分担, 春学期 AB, 金34)</li>
	<li>アドバンストCG (分担, 春学期 AB, 木56)</li>
	<li>データサイエンス (総学第3類DE班、秋学期 AB, 月56)</li>
	<li><a href="http://kanamori.cs.tsukuba.ac.jp/dl_jikken">情報メディア創成学類: 情報メディア実験 B・情報科学類: 知能情報メディア実験</a></li>
</ol>
<h3 class="h5 mr-2 font-weight-bold">2020年度</h3>
<ol>
	<li>コンピュータグラフィックス基礎 (CG 基礎) (分担, 春学期 AB, 金34)</li>
	<li>CG特論 (分担, 春学期 AB, 木12)</li>
	<li>データサイエンス (物理2班、秋学期 AB, 水12)</li>
	<li>データサイエンス (芸術1班、秋学期 AB, 金12)</li>
</ol>
<h3 class="h5 mr-2 font-weight-bold">2019年度</h3>
<ol>
	<li>情報・知能工学基礎実験 (計算機基礎ⅡⅢ) (前期)</li>
	<li>情報・知能工学実験 (論理回路) (前期)</li>
	<li>コンピュータグラフィックス基礎 (CG 基礎) (分担、秋学期 AB)</li>
	<li>データサイエンス (秋学期 AB, 水1,2)</li>
</ol>
<h3 class="h5 mr-2 font-weight-bold">2018年度</h3>
<ol>
	<li>共通科目情報(上級) (プログラミング言語Java) (春学期 AB 月4,5)</li>
	<li>共通科目情報(実習) (春学期 AB 火3,4)</li>
	<li>CG特論 / バーチャル空間モデリング(分担、春学期 AB 木1,2)</li>
	<li>マルチメディアの舞台裏：コンテンツを創るための実世界指向技術 (春学期 AB 1回分)</li>
	<li>情報科学概論Ｉ (春学期 C 1回分)</li>
</ol>

<h3 class="h5 mr-2 font-weight-bold">2017年度</h3>
<ol>
	<li>共通科目情報(上級) (プログラミング言語Java) (春学期 AB 月4,5)</li>
	<li>共通科目情報(実習) (春学期 AB 火3,4)</li>
	<li>マルチメディアの舞台裏：コンテンツを創るための実世界指向技術 (春学期 AB 5/9 月1,2)</li>
	<li>情報科学概論Ｉ (春学期 C 7/21 金3,4)</li>
	<li>コンピュータグラフィクス基礎 (CG 基礎) (分担、秋学期 AB)</li>
</ol>

<h3 class="h5 mr-2 font-weight-bold">2016年度</h3>

<ol>
	<li>CG・インタフェース特論 / バーチャル空間モデリング(分担、秋学期 AB)</li>
	<li>コンピュータグラフィクス基礎 (CG 基礎) (分担、秋学期 AB)</li>
</ol>
</section>

<!-- *************************************************************** -->
<div class="footer footer-copyright text-center bg-dark text-light"> <span class="small">2024 &copy; Yuki Endo All Rights Reserved.</span>
    <div class="float-right bg-secondary col-sm-1"> <a href="#"> <i class="fas fa-arrow-up text-light"></i> </a> </div>
</div>    
</footer>
<!-- *************************************************************** -->    
<!-- javascript はここから --> 
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>    
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script> 
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script> 
<script type="text/javascript" src="js/script.js"></script>
</body>
</html>
